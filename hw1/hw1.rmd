---
title: HW 1
output: pdf_document
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(raster)
```

# Problem 1
```{r message=FALSE, warning=FALSE}
N_seq <- seq(100, 2000, 100)
cpu_time <- matrix(NA, nrow = length(N_seq), ncol = 2)
for (i in seq_along(N_seq)) {
  ## direct use solve
  M <- 10; sigma <- 0.2
  N <- N_seq[i]
  K <- matrix(rnorm(N*M), nrow=N, ncol=M)
  Sigma <- sigma*diag(rep(1,N))+K%*%t(K)
  t1 <- system.time(solve(Sigma))
  cpu_time[i, 1] <- t1[3]

  ## Sherman-Morrison-Woodbury identity
  I <- diag(rep(1,N))
  C <- sigma * diag(rep(1,M))
  ptm <- proc.time()
  Sigma_inv <- (1/sigma) * (I - K %*% solve(C + t(K)%*%K) %*% t(K))
  t2 <- proc.time() - ptm
  cpu_time[i, 2] <- t2[3]
}
```

```{r message=FALSE, warning=FALSE}
alg_one <- function(N, M){
  y = N*N*N + 2*N*M + N*N
  return(y)
}

alg_two <- function(N, M){
  y = N*N + 2*N*M*M + N*N*M + M*M*M + M*M
  return(y)
}

N <- seq(1, 100, 1)
y1 <- alg_one(N = N, M = 10)
y2 <- alg_two(N = N, M = 10)
plot(N, y1, type ='l', col = 'red', xlab = "N", ylab = "FLOPs")
abline(N, y2, col = "blue")
legend("topleft", legend = c("direct use solve",
  "Sherman-Morrison-Woodbury identity"), col = c("red", "blue"), lty = 1)
```

```{r message=FALSE, warning=FALSE}
plot(seq_along(N_seq), cpu_time[, 1],
  type = "l", col = "red",
  xlab = "N", ylab = "CPU time (s)")
lines(seq_along(N_seq), cpu_time[, 2], col = "blue")
legend("topleft", legend = c("direct use solve",
  "Sherman-Morrison-Woodbury identity"), col = c("red", "blue"), lty = 1)
```

# Problem 2
```{r message=FALSE, warning=FALSE}
GSE1000 <- read.csv("./GSE1000_series_matrix.csv")
gse_data <- GSE1000[, 2:11]
gse_data <- scale(gse_data, center = TRUE, scale = FALSE)
```

## (a)
```{r message=FALSE, warning=FALSE}
gse_svd <- svd(gse_data)
gse_u <- gse_svd$u
gse_d <- gse_svd$d
gse_vt <- t(gse_svd$v)
image(gse_vt, xlab = "Arrays", ylab = "Eigenvalues")
```

## (b)
```{r message=FALSE, warning=FALSE}
p <- gse_d^2 / sum(gse_d^2)
p <- sort(p, decreasing = FALSE)
barplot(p, names.arg = 1:10, horiz = TRUE)
```

```{r message=FALSE, warning=FALSE}
entropy <- -1/log(10) * sum(p * log(p))
entropy
```

## (c)
```{r message=FALSE, warning=FALSE}
plot(1:10, gse_vt[1, ],
  col = "red",
  type = "l",
  ylim = c(-1, 1))
lines(1:10, gse_vt[2, ], col = "blue")
abline(h = 0)
```

## (d)
```{r message=FALSE, warning=FALSE}
plot(raster(gse_u), xlab = "Arrays", ylab = "Genes")
```

# Problem 3
```{r}
## Problem 3
N <- seq(20, 1000, 100)
direct_est <- rgamma(20, shape = 3, scale = 7)
direct_est <- c()
mse_MLE <- c()
bias_MLE <- c()
mse_M <- c()
bias_M <- c()
alpha_MLE <- c()
beta_MLE <- c()
alpha_M <- c()
beta_M <- c()
## Estimation using different methods

for (i in 1:length(N)){
  direct_est <- rgamma(N[i], shape = 3, scale = 7)
  ## Estimation MLE method
  mu <- mean(direct_est)
  sigma2 <- var(direct_est)
  s <- log(mu) - mean(log(direct_est))
  alpha_MLE[i] <- (3 - s + sqrt((s-3)*(s-3) + 24*s))/(12 * s)
  beta_MLE[i] <- mu/alpha_MLE[i]
  
  ## Estimation Moment method
  alpha_M[i] <- mu*mu/sigma2
  beta_M[i] <- sigma2/mu
}
```
# Problem 4
```{r message=FALSE, warning=FALSE}
mcmc <- function(N, m, func) {
  sample_mcmc <- c()
  for (i in 1:N) {
    R <- matrix(rnorm(m*m, 0, 1), m, m)
    Sigma <- R %*% t(R)
    sample_mcmc <- c(sample_mcmc, func(Sigma))
  }
  return(list(sample = sample_mcmc, se = sd(sample_mcmc) / sqrt(N)))
}
```

## (a)
```{r message=FALSE, warning=FALSE}
trace <- function(X) sum(diag(X))

## m = 100
trace_mcmc <- mcmc(1000, 100, trace)
hist(trace_mcmc$sample)
print(trace_mcmc$se)

## m = 1000
trace_mcmc <- mcmc(1000, 1000, trace)
hist(trace_mcmc)
print(trace_mcmc$se)
```

## (b)
```{r message=FALSE, warning=FALSE}
max_eignval <- function(X) {
  eigen(X)$values[1]
}

## m = 100
eig_mcmc <- mcmc(1000, 100, max_eignval)
hist(eig_mcmc$sample)
print(eig_mcmc$se)

## m = 1000
eig_mcmc <- mcmc(1000, 1000, trace)
hist(eig_mcmc)
print(eig_mcmc$se)
```

## (c)
```{r message=FALSE, warning=FALSE}
eig_exp <- c()
for (m in 1:100) {
  eig_mcmc <- mcmc(1000, m, max_eignval)
  eig_exp <- c(eig_exp, mean(eig_mcmc))
  cat(m, "\r")
}
plot(1:100, eig_exp, type = "l")
```

## (d)


# Problem 5
## Serial optimization
We first note that $sin(x)^2 - cos(x)^2 = -cos(2x)$, which can be used to calculate "cos_val". Second, we leverage R's vectorization techniques for efficient computation of "cos_vals" and "v_mat". Specifically, when a vector is passed to the cosine function, R computes the cosine values for each element within the vector. Furthermore, when performing an element-wise product between a vector and a matrix, R broadcasts the vector to match the dimensions of the matrix.

```{r eval=FALSE, message=FALSE, warning=FALSE}
myfunc <- function(v_s, i_v, iter)
{
  d_vals <- round(i_v %% 256)
  cos_vals <- -cos(2 * d_vals)
  v_mat <- v_s * cos_vals;
  return(v_mat/cos(iter))
}
```

We are able to reduce the user running time from 104.307 seconds to 1.023 seconds.

## Parallel computing
For parallel computing, we use the "doMC" package to register the requested cores, and use "foreach" package to assign jobs for each worker.
```{r eval=FALSE, message=FALSE, warning=FALSE}
library(doMC)
library(foreach)

## register workers
args = commandArgs(trailingOnly=TRUE)
num_cores <- as.numeric(args[1])
registerDoMC(num_cores)
```

```{r eval=FALSE, message=FALSE, warning=FALSE}
## Use foreach and print time
ptm <- proc.time()
Res <- foreach(i = 1:num_cores, .combine = c) %dopar% {
  res_mat <- myfunc(vd_s, vi_v, iter)
  mean(res_mat)
}
print(proc.time() - ptm)
```

We repeat this procedure n times, where n is chosen from {1, 4, 8, 16, 32, 64}. We plot the running time plot below.
```{r echo=FALSE, message=FALSE, warning=FALSE}
plot(1:6, c(1.340, 1.047, 0.931, 1.491, 1.337, 0.965),
  type="l", xlab='number of cores', ylab = "running time", xaxt = "n")
axis(1, at=1:6, labels=c(1, 4, 8, 16, 32, 64))
```

# Problem 6
```{python eval=FALSE, python.reticulate = FALSE}
import numpy as np
mat = np.loadtxt('Mat.dat')
np.savetxt("Mat_T.dat", mat.T)

print(np.mean(mat[:, 0]))
print(np.mean(mat[:, 2]))
```
0.04475862857142858, 0.620249032857143

```{r eval=FALSE, message=FALSE, warning=FALSE}
mat_t <- as.matrix(read.table("Mat_T.dat"))
mean(mat_t[1, ])
mean(mat_t[3, ])
```
0.04475863, 0.620249
